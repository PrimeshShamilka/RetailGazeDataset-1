GOO-real consists of both dense and sparse setups.
You can download GOO-real in the following link:

ImageData link (5/31/2021): https://zenodo.org/record/5795240/files/gooreal.zip?download=1
testrealhumans.pickle (5/31/2021): https://zenodo.org/record/5795290/files/testrealhumansNew.pickle?download=1
oneshotrealhumans.pickle (5/31/2021): https://zenodo.org/record/5795284/files/oneshotrealhumansNew.pickle?download=1
valrealhumans.pickle (5/31/2021): https://zenodo.org/record/5795283/files/valrealhumansNew.pickle?download=1
testrealhumansSparsed.pickle (5/31/2021): https://zenodo.org/record/5795279/files/testrealhumansSparsedNew.pickle?download=1

The main directory for dense set GOO-real is "finalrealdatasetImgsV3". Its pickle files are:
oneshotrealhumans.pickle - used for one-shot training
testrealhumans.pickle - used for testing
valrealhumans.pickle - used for validation

The main directory for sparse set GOO-real is "finalrealdatasetImgsV3Sparsed". Its pickle files are:
testrealhumansSparsed.pickle - used for testing

Update (12/21/2021): Pickle files have "New" name at the end. Rename if you want.

The contents of the pickle files are a list of dictionary objects with length equal to the total number of images. Each dictionary contains the following data:

data_dict = {
    'filename': "the filename tree of this image",
    'width': "1920width",
    'height': "1080height",
    'ann': {
        'bboxes': "This is a list of bounding boxes. Each element has the contents [xmin, ymin, xmax, ymax]. The last bounding box is the head of the person in the image.",
        'labels': "This is the class label of the ith index of 'bboxes' data. The class label ranges from 1-24. The last label is -1.",
        'bboxes_ignore': "Not important",
        'labels_ignore': "Not important",
        'gt_bboxes_ignore': "Not important",
        'gt_labels_ignore': "Not important",
        },
    'gaze_item': "This is the class (1-24) of the gazed grocery item",
    'gazeIdx': "This contains the index of 'bboxes' (0 to len(bboxes)) which refers to the gazed item's bounding box",
    'gaze_cx': "This is the specific point gx in the image that is considered the gazepoint. It should be inside the gazed bounding box.",
    'gaze_cy': "This is the specific point gy in the image that is considered the gazepoint. It should be inside the gazed bounding box.",
    'hx': "This is the point X in the head bounding box. Use this to draw a line to the gazepoint to form a gazeline.",
    'hy': "This is the point Y in the head bounding box. Use this to draw a line to the gazepoint to form a gazeline.",
    'seg': "Contains the segmentation of the gazed object item. This contains a list of pixels [cx, cy] that refer to the gazed object.",
    'cam:': "Not important",
    'occluded': "Not important",
}

NOTE:
Please note that the image file is in 1920X1080 format. However, the bounding box data, [xmin, ymin, xmax, ymax], and segmentation data [cx, cy], gazepoint [gx, gy], headpoint [hx, hy] are all in the scales of 640X480.
You can, for example, use cv.resize(img, (640, 480)) in python to train the data (no need to rescale data other than the image size only).
