{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import cv2\n",
    "\n",
    "from utils_logging import setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose between Recasens or GazeNet\n",
    "\n",
    "- Idea is you can just swap \n",
    "models.recasens, dataloader.recasens, training.train_recasens, etc...\n",
    "- with the following\n",
    "models.gazenet, dataloader.gazenet, training.train_gazenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.chong import ModelSpatial\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from dataloader.chong import GazeDataset, GooDataset\n",
    "from dataloader import chong_imutils\n",
    "from training.train_chong import train, test, GazeOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger will save the training and test errors to a .log file \n",
    "logger = setup_logger(name='first_logger',\n",
    "                      log_dir ='./logs/',\n",
    "                      log_file='train_chong_gooreal.log',\n",
    "                      log_format = '%(asctime)s %(levelname)s %(message)s',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dataloaders\n",
    "- Choose between GazeDataset (Gazefollow dataset) or GooDataset (GooSynth/GooReal)\n",
    "- Set paths to image directories and pickle paths. For Gazefollow, images_dir and test_images_dir should be the same and both lead to the path containing the train and test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 172800\n",
      "Number of Images: 19200\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Synth\n",
    "batch_size=32\n",
    "workers=12\n",
    "\n",
    "images_dir = '/hdd/HENRI/goosynth/1person/GazeDatasets/'\n",
    "pickle_path = '/hdd/HENRI/goosynth/picklefiles/trainpickle2to19human.pickle'\n",
    "test_images_dir = '/hdd/HENRI/goosynth/test/'\n",
    "test_pickle_path = '/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\n",
    "\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 2451\n",
      "Number of Images: 2156\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Real\n",
    "batch_size=32\n",
    "workers=12\n",
    "\n",
    "images_dir = '/home/eee198/Documents/datasets/GOOReal/finalrealdatasetImgsV2/'\n",
    "pickle_path = '/home/eee198/Documents/datasets/GOOReal/oneshotrealhumans.pickle'\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GOOReal/finalrealdatasetImgsV2/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GOOReal/testrealhumans.pickle'\n",
    "\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders for GAZE\n",
    "\n",
    "batch_size=32\n",
    "workers=12\n",
    "testbatchsize=16\n",
    "\n",
    "images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/train_annotations.mat'\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/test_annotations.mat'\n",
    "\n",
    "train_set = GazeDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GazeDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Model and Set Training Hyperparameters\n",
    "- For Gazefollow, the model requires the alexnet_places365 pretrained model, provided here: https://urlzs.com/ytKK3\n",
    "- When resuming training, set to True and set the resume_path for the saved model.\n",
    "- Here, logging module is initialized (logger) to save training and testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Constructing model\n",
      "==> Loading initial weights\n",
      "=> loading checkpoint './saved_models/chong_goosynth/model_epoch25.pth.tar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/anaconda3/envs/gazefollow/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "\r",
      "  0%|          | 0/135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint './saved_models/chong_goosynth/model_epoch25.pth.tar' (epoch 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:14<00:00,  9.14it/s]\n",
      "average error: [0.7097163551286596, 0.25522330364427304, 47.91783339325987]\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/s9y65ajzjz4thve/initial_weights_for_spatial_training.pt\n",
    "init_weights = 'initial_weights_for_spatial_training.pt'\n",
    "\n",
    "# Loads model\n",
    "print(\"==> Constructing model\")\n",
    "net = ModelSpatial()\n",
    "net.cuda()\n",
    "\n",
    "# Hyperparameters\n",
    "start_epoch = 0\n",
    "max_epoch = 5\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# Initial weights chong\n",
    "print(\"==> Loading initial weights\")\n",
    "model_dict = net.state_dict()\n",
    "pretrained_dict = torch.load(init_weights)\n",
    "pretrained_dict = pretrained_dict['model']\n",
    "model_dict.update(pretrained_dict)\n",
    "net.load_state_dict(model_dict)\n",
    "\n",
    "# Initializes Optimizer\n",
    "gaze_opt = GazeOptimizer(net, learning_rate)\n",
    "optimizer = gaze_opt.getOptimizer(start_epoch)\n",
    "\n",
    "# Resuming Training\n",
    "resume_training = True\n",
    "resume_path = './saved_models/chong_goosynth/model_epoch25.pth.tar'\n",
    "if resume_training:\n",
    "    net, optimizer, _ = resume_checkpoint(net, optimizer,resume_path)\n",
    "    test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/anaconda3/envs/gazefollow/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|██████████| 135/135 [00:15<00:00,  8.93it/s]\n",
      "average error: [0.6637493906421568, 0.33433772442945553, 66.62653383895953]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6637493906421568, 0.33433772442945553, 66.62653383895953]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training the Model\n",
    "- Determine in which epochs do you want to save the model, as you might not want to save every epoch\n",
    "- Training and test errors can be accessed in the logs directory set up earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/anaconda3/envs/gazefollow/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|██████████| 77/77 [00:38<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 77/77 [00:39<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 77/77 [00:39<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 77/77 [00:39<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "best_l2 = np.inf\n",
    "\n",
    "for epoch in range(1,5):\n",
    "\n",
    "    # Update optimizer\n",
    "    optimizer = gaze_opt.getOptimizer(epoch)\n",
    "\n",
    "    # Train model\n",
    "    print('training')\n",
    "    train(net, train_data_loader, optimizer, epoch, logger)\n",
    "\n",
    "    # Evaluate model\n",
    "    #scores = test(net, test_data_loader, logger)\n",
    "    \n",
    "    # Save model+optimizer with best L2 Scorehttp://localhost:8888/notebooks/train_chong.ipynb#\n",
    "    #if scores[1] < best_l2:\n",
    "    #    best_l2 = scores[1]\n",
    "    #    save_path = './saved_models/chong_gooreal_notrained/'\n",
    "    #    save_checkpoint(net, optimizer, 420, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:16<00:00,  8.39it/s]\n",
      "average error: [0.8613018095794566, 0.1459625192366771, 26.391563159013245]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8613018095794566, 0.1459625192366771, 26.391563159013245]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
