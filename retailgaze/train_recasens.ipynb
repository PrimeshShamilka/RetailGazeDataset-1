{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import itertools\n",
    "from scipy.io import  loadmat\n",
    "import logging\n",
    "from scipy import signal\n",
    "\n",
    "from utils import data_transforms\n",
    "from utils import get_paste_kernel, kernel_map\n",
    "from utils_logging import setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose between Recasens or GazeNet\n",
    "\n",
    "- Idea is you can just swap \n",
    "models.recasens, dataloader.recasens, training.train_recasens, etc...\n",
    "- with the following\n",
    "models.gazenet, dataloader.gazenet, training.train_gazenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.recasens import GazeNet\n",
    "from dataloader.recasens import GooDataset, GazeDataset\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from training.train_recasens import train, test, GazeOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger will save the training and test errors to a .log file \n",
    "logger = setup_logger(name='first_logger', \n",
    "                      log_dir ='./logs/',\n",
    "                      log_file='train_recasens_newauc.log',\n",
    "                      log_format = '%(asctime)s %(levelname)s %(message)s',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dataloaders\n",
    "- Choose between GazeDataset (Gazefollow dataset) or GooDataset (GooSynth/GooReal)\n",
    "- Set paths to image directories and pickle paths. For Gazefollow, images_dir and test_images_dir should be the same and both lead to the path containing the train and test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders for GazeFollow\n",
    "batch_size=64\n",
    "workers=12\n",
    "testbatchsize=batch_size*2\n",
    "\n",
    "images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/train_annotations.mat'\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/test_annotations.mat'\n",
    "\n",
    "train_set = GazeDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "val_set = GazeDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = torch.utils.data.DataLoader(val_set, batch_size=testbatchsize, num_workers=workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in this set: 172800\n",
      "Total images in this set: 19200\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Synth\n",
    "batch_size=32\n",
    "workers=12\n",
    "testbatchsize=32\n",
    "\n",
    "images_dir = '/hdd/HENRI/goosynth/1person/GazeDatasets/'\n",
    "pickle_path = '/hdd/HENRI/goosynth/picklefiles/trainpickle2to19human.pickle'\n",
    "test_images_dir = '/hdd/HENRI/goosynth/test/'\n",
    "test_pickle_path = '/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\n",
    "\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "val_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = torch.utils.data.DataLoader(val_set, batch_size=testbatchsize, num_workers=workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in this set: 2451\n",
      "Total images in this set: 2156\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Real\n",
    "\n",
    "batch_size=32\n",
    "workers=12\n",
    "testbatchsize=32\n",
    "\n",
    "images_dir = '/home/eee198/Documents/datasets/GOOReal/finalrealdatasetImgsV2/'\n",
    "pickle_path = '/home/eee198/Documents/datasets/GOOReal/oneshotrealhumans.pickle'\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GOOReal/finalrealdatasetImgsV2/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GOOReal/testrealhumans.pickle'\n",
    "\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "val_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = torch.utils.data.DataLoader(val_set, batch_size=testbatchsize, num_workers=workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Model and Set Training Hyperparameters\n",
    "- For Gazefollow, the model requires the alexnet_places365 pretrained model, provided here: https://urlzs.com/ytKK3\n",
    "- When resuming training, set to True and set the resume_path for the saved model.\n",
    "- Here, logging module is initialized (logger) to save training and testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/completed/recasens_goo_epoch4.pth.tar'\n",
      "=> loaded checkpoint './saved_models/completed/recasens_goo_epoch4.pth.tar' (epoch 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [01:21<00:00,  1.20s/it]\n",
      "proximate accuracy: [0.00231911 0.00974026 0.02365492 0.10204082 0.22588126 0.32235622\n",
      " 0.43599258 0.53339518]\n",
      "average error: [0.7020923813740372, 0.31269916848244217, 73.99956924930054]\n"
     ]
    }
   ],
   "source": [
    "# Loads model\n",
    "net = GazeNet(placesmodel_path='./alexnet_places365.pth')\n",
    "net.cuda()\n",
    "\n",
    "# Hyperparameters\n",
    "start_epoch = 0\n",
    "max_epoch = 5\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Initializes Optimizer\n",
    "gaze_opt = GazeOptimizer(net, learning_rate)\n",
    "optimizer = gaze_opt.getOptimizer(start_epoch)\n",
    "\n",
    "# Is training resumed? If so, set the resume_path and set flag to True\n",
    "resume_training = True\n",
    "resume_path = './saved_models/completed/recasens_goo_epoch4.pth.tar'\n",
    "if resume_training :\n",
    "    net, optimizer, _ = resume_checkpoint(net, optimizer, resume_path)\n",
    "    test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [01:23<00:00,  1.23s/it]\n",
      "proximate accuracy: [0.00046382 0.00463822 0.01205937 0.03942486 0.07977737 0.16233766\n",
      " 0.25695733 0.33534323]\n",
      "average error: [0.4597496690213444, 0.3882146535767388, 68.89116375273363]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4597496690213444, 0.3882146535767388, 68.89116375273363]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training the Model\n",
    "- Determine in which epochs do you want to save the model, as you might not want to save every epoch\n",
    "- Training and test errors can be accessed in the logs directory set up earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:35<00:00,  1.24s/it]\n",
      "100%|██████████| 77/77 [01:37<00:00,  1.27s/it]\n",
      "100%|██████████| 77/77 [01:38<00:00,  1.28s/it]\n",
      "100%|██████████| 77/77 [01:39<00:00,  1.29s/it]\n",
      "100%|██████████| 68/68 [01:24<00:00,  1.24s/it]\n",
      "proximate accuracy: [0.00278293 0.02922078 0.06957328 0.23237477 0.466141   0.64007421\n",
      " 0.7458256  0.82792208]\n",
      "average error: [0.903229810803981, 0.1952449509308719, 39.84618047878634]\n"
     ]
    }
   ],
   "source": [
    "best_l2 = np.inf\n",
    "\n",
    "for epoch in range(1,5):\n",
    "    \n",
    "    # Update optimizer\n",
    "    optimizer = gaze_opt.getOptimizer(epoch)\n",
    "\n",
    "    # Train model\n",
    "    train(net, train_data_loader, optimizer, epoch, logger)\n",
    "    \n",
    "    # Evaluate model\n",
    "    if epoch+1 in [1,5]:\n",
    "        scores = test(net, test_data_loader, logger, save_output=True)\n",
    "    \n",
    "    # Save model+optimizer with best L2 Score\n",
    "    #if scores[1] < best_l2:\n",
    "    #    best_l2 = scores[1]\n",
    "    #    save_path = './saved_models/recasens_gooreal_notrain/'\n",
    "    #    save_checkpoint(net, optimizer, 0, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [01:23<00:00,  1.23s/it]\n",
      "proximate accuracy: [0.00092764 0.00742115 0.02179963 0.06307978 0.12337662 0.20269017\n",
      " 0.30333952 0.40862709]\n",
      "average error: [0.6879634857505997, 0.3473641554752535, 75.32601067892568]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6879634857505997, 0.3473641554752535, 75.32601067892568]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(net, test_data_loader, logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
