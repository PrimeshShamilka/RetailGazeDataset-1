{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import itertools\n",
    "from scipy.io import  loadmat\n",
    "import logging\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from utils import data_transforms\n",
    "\n",
    "from models.chong import ModelSpatial as GazeNet\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from dataloader.chong import GazeDataset, GooDataset\n",
    "from dataloader import chong_imutils\n",
    "from training.train_chong import train, test, GazeOptimizer\n",
    "\n",
    "def generate_data_field(eye_point):\n",
    "    \"\"\"eye_point is (x, y) and between 0 and 1\"\"\"\n",
    "    height, width = 224, 224\n",
    "    x_grid = np.array(range(width)).reshape([1, width]).repeat(height, axis=0)\n",
    "    y_grid = np.array(range(height)).reshape([height, 1]).repeat(width, axis=1)\n",
    "    grid = np.stack((x_grid, y_grid)).astype(np.float32)\n",
    "\n",
    "    x, y = eye_point\n",
    "    x, y = x * width, y * height\n",
    "\n",
    "    grid -= np.array([x, y]).reshape([2, 1, 1]).astype(np.float32)\n",
    "    norm = np.sqrt(np.sum(grid ** 2, axis=0)).reshape([1, height, width])\n",
    "    # avoid zero norm\n",
    "    norm = np.maximum(norm, 0.1)\n",
    "    grid /= norm\n",
    "    return grid\n",
    "\n",
    "def preprocess_image(image_path, eye):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # crop face\n",
    "    x_c, y_c = eye\n",
    "    x_0 = x_c - 0.15\n",
    "    y_0 = y_c - 0.15\n",
    "    x_1 = x_c + 0.15\n",
    "    y_1 = y_c + 0.15\n",
    "    if x_0 < 0:\n",
    "        x_0 = 0\n",
    "    if y_0 < 0:\n",
    "        y_0 = 0\n",
    "    if x_1 > 1:\n",
    "        x_1 = 1\n",
    "    if y_1 > 1:\n",
    "        y_1 = 1\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    face_image = image[int(y_0 * h):int(y_1 * h), int(x_0 * w):int(x_1 * w), :]\n",
    "    # process face_image for face net\n",
    "    face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "    face_image = Image.fromarray(face_image)\n",
    "    face_image = data_transforms['test'](face_image)\n",
    "    # process image for saliency net\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    image = data_transforms['test'](image)\n",
    "\n",
    "    # generate gaze field\n",
    "    gaze_field = generate_data_field(eye_point=eye)\n",
    "    sample = {'image' : image,\n",
    "              'face_image': face_image,\n",
    "              'eye_position': torch.FloatTensor(eye),\n",
    "              'gaze_field': torch.from_numpy(gaze_field)}\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "\n",
    "def test_on_batch(net, dataloader, heatmap_size=64, save_dir='./sample_out/'):\n",
    "    net.eval()\n",
    "    heatmaps = []\n",
    "    \n",
    "    data = next(iter(dataloader))\n",
    "    \n",
    "    val_img, val_face, val_head_channel, eye_position, \\\n",
    "    val_gaze_heatmap, gaze, gaze_inside, image_paths, gt_box = data\n",
    "\n",
    "    val_images = val_img.cuda()\n",
    "    val_head = val_head_channel.cuda()\n",
    "    val_faces = val_face.cuda()\n",
    "    val_gaze_heatmap = val_gaze_heatmap.cuda()\n",
    "    val_gaze_heatmap_pred, val_attmap, val_inout_pred = net(val_images, val_head, val_faces)\n",
    "    val_gaze_heatmap_pred = val_gaze_heatmap_pred.squeeze(1)\n",
    "    \n",
    "    # Obtaining eval metrics\n",
    "    final_output = val_gaze_heatmap_pred.cpu().data.numpy() \n",
    "\n",
    "    gaze_x, gaze_y = gaze\n",
    "    gaze_x_cpu = gaze_x.cpu().data.numpy()\n",
    "    gaze_y_cpu = gaze_y.cpu().data.numpy()\n",
    "    gt_position = np.array([gaze_x_cpu, gaze_y_cpu]).T\n",
    "\n",
    "    eye_x, eye_y = eye_position\n",
    "    eye_x_cpu = eye_x.cpu().data.numpy()\n",
    "    eye_y_cpu = eye_y.cpu().data.numpy()\n",
    "    eye_position = np.array([eye_x_cpu, eye_y_cpu]).T\n",
    "    \n",
    "    gt_box = gt_box.numpy()\n",
    "\n",
    "    N = val_img.shape[0]\n",
    "    \n",
    "    for idx in range(N):\n",
    "\n",
    "        heatmap = final_output[idx].reshape([heatmap_size, heatmap_size])\n",
    "\n",
    "        h_index, w_index = np.unravel_index(heatmap.argmax(), heatmap.shape)\n",
    "        f_point = np.array([w_index / heatmap_size, h_index / heatmap_size])\n",
    "        \n",
    "        draw_result(image_paths[idx], eye_position[idx], heatmap, f_point, gt_position[idx],\\\n",
    "                    gt_box[idx], save_dir=save_dir, idx=idx)\n",
    "\n",
    "def draw_result(image_path, eye, heatmap, gaze_point, gt_point, gt_box, save_dir, idx=0):\n",
    "    \n",
    "    im = cv2.imread(image_path)\n",
    "    im_static = np.copy(im)\n",
    "    \n",
    "    x1, y1 = eye\n",
    "    x2, y2 = gaze_point\n",
    "    x3, y3 = gt_point\n",
    "    \n",
    "    image_height, image_width = im.shape[:2]\n",
    "    x1, y1 = image_width * x1, y1 * image_height\n",
    "    x2, y2 = image_width * x2, y2 * image_height\n",
    "    x3, y3 = image_width * x3, y3 * image_height\n",
    "    x1, y1, x2, y2, x3, y3 = map(int, [x1, y1, x2, y2, x3, y3])\n",
    "    #cv2.circle(im, (x1, y1), 10, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x2, y2), 15, [0, 0, 255], -1)\n",
    "    cv2.circle(im, (x3, y3), 15, [0, 255, 0], -1)\n",
    "    cv2.line(im, (x1, y1), (x2, y2), [0, 0, 255], 8)\n",
    "    cv2.line(im, (x1, y1), (x3, y3), [0, 255, 0], 8)\n",
    "    \n",
    "    # Drawing the GT bounding box\n",
    "    gt_box = gt_box * [image_width, image_height, image_width, image_height]\n",
    "    gt_box = gt_box.astype(int)\n",
    "    cv2.rectangle(im, (gt_box[0], gt_box[1]), (gt_box[2], gt_box[3]), (0,255,0), 6)\n",
    "\n",
    "    # heatmap visualization\n",
    "    heatmap = ((heatmap - heatmap.min()) / (heatmap.max() - heatmap.min()) * 255).astype(np.uint8)\n",
    "    heatmap = cv2.resize(heatmap, (image_width, image_height))\n",
    "    \n",
    "    colormap = plt.get_cmap('gnuplot2')\n",
    "    #colormap = plt.get_cmap('magma')\n",
    "    heatmap = (colormap(heatmap)*255).astype(np.uint16)[:,:,:3]\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    heatmap = (0.75 * heatmap.astype(np.float32) + 0.25 * im_static.astype(np.float32)).astype(np.uint8)\n",
    "    img = np.concatenate((im, heatmap), axis=1)   \n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    filename = 'out_%s.png' % str(idx)\n",
    "    save_path = save_dir + filename\n",
    "    print(save_path)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 2156\n"
     ]
    }
   ],
   "source": [
    "from utils_logging import setup_logger\n",
    "\n",
    "# Logger will save the training and test errors to a .log file \n",
    "logger = setup_logger(name='first_logger',\n",
    "                      log_dir ='./logs/',\n",
    "                      log_file='modeltester.log',\n",
    "                      log_format = '%(asctime)s %(levelname)s %(message)s',\n",
    "                      verbose=True)\n",
    "\n",
    "#Prepare dataloaders\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GOOReal/finalrealdatasetImgsV2/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GOOReal/testrealhumans.pickle'\n",
    "batch_size = 32\n",
    "\n",
    "val_set = GooDataset(test_images_dir, test_pickle_path, 'test', use_gtbox=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GOO-Synth Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/chong_gooreal_final/model_5epochs_pretrain.tar'\n",
      "=> Optimizer has different parameter groups. Usually this will occur for staged optimizers (GazeNet, GazeMask)\n",
      "=> loaded checkpoint './saved_models/chong_gooreal_final/model_5epochs_pretrain.tar' (epoch 420)\n",
      "./sample_out_pretrained/out_0.png\n",
      "./sample_out_pretrained/out_1.png\n",
      "./sample_out_pretrained/out_2.png\n",
      "./sample_out_pretrained/out_3.png\n",
      "./sample_out_pretrained/out_4.png\n",
      "./sample_out_pretrained/out_5.png\n",
      "./sample_out_pretrained/out_6.png\n",
      "./sample_out_pretrained/out_7.png\n",
      "./sample_out_pretrained/out_8.png\n",
      "./sample_out_pretrained/out_9.png\n",
      "./sample_out_pretrained/out_10.png\n",
      "./sample_out_pretrained/out_11.png\n",
      "./sample_out_pretrained/out_12.png\n",
      "./sample_out_pretrained/out_13.png\n",
      "./sample_out_pretrained/out_14.png\n",
      "./sample_out_pretrained/out_15.png\n",
      "./sample_out_pretrained/out_16.png\n",
      "./sample_out_pretrained/out_17.png\n",
      "./sample_out_pretrained/out_18.png\n",
      "./sample_out_pretrained/out_19.png\n",
      "./sample_out_pretrained/out_20.png\n",
      "./sample_out_pretrained/out_21.png\n",
      "./sample_out_pretrained/out_22.png\n",
      "./sample_out_pretrained/out_23.png\n",
      "./sample_out_pretrained/out_24.png\n",
      "./sample_out_pretrained/out_25.png\n",
      "./sample_out_pretrained/out_26.png\n",
      "./sample_out_pretrained/out_27.png\n",
      "./sample_out_pretrained/out_28.png\n",
      "./sample_out_pretrained/out_29.png\n",
      "./sample_out_pretrained/out_30.png\n",
      "./sample_out_pretrained/out_31.png\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "net = GazeNet()\n",
    "net.cuda()\n",
    "\n",
    "# Resuming Training\n",
    "resume_training = True\n",
    "resume_path = './saved_models/chong_gooreal_final/model_5epochs_pretrain.tar'\n",
    "if resume_training:\n",
    "    net, _, _ = resume_checkpoint(net, None,resume_path)\n",
    "    #test(net, test_data_loader,logger, save_output=True)\n",
    "\n",
    "\n",
    "test_on_batch(net, test_data_loader, heatmap_size=64, save_dir='./sample_out_pretrained/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Pretraining on GOO-Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/chong_gooreal_final/model_5epochs_notrain.tar'\n",
      "=> Optimizer has different parameter groups. Usually this will occur for staged optimizers (GazeNet, GazeMask)\n",
      "=> loaded checkpoint './saved_models/chong_gooreal_final/model_5epochs_notrain.tar' (epoch 25)\n",
      "./sample_out_nopretrain/out_0.png\n",
      "./sample_out_nopretrain/out_1.png\n",
      "./sample_out_nopretrain/out_2.png\n",
      "./sample_out_nopretrain/out_3.png\n",
      "./sample_out_nopretrain/out_4.png\n",
      "./sample_out_nopretrain/out_5.png\n",
      "./sample_out_nopretrain/out_6.png\n",
      "./sample_out_nopretrain/out_7.png\n",
      "./sample_out_nopretrain/out_8.png\n",
      "./sample_out_nopretrain/out_9.png\n",
      "./sample_out_nopretrain/out_10.png\n",
      "./sample_out_nopretrain/out_11.png\n",
      "./sample_out_nopretrain/out_12.png\n",
      "./sample_out_nopretrain/out_13.png\n",
      "./sample_out_nopretrain/out_14.png\n",
      "./sample_out_nopretrain/out_15.png\n",
      "./sample_out_nopretrain/out_16.png\n",
      "./sample_out_nopretrain/out_17.png\n",
      "./sample_out_nopretrain/out_18.png\n",
      "./sample_out_nopretrain/out_19.png\n",
      "./sample_out_nopretrain/out_20.png\n",
      "./sample_out_nopretrain/out_21.png\n",
      "./sample_out_nopretrain/out_22.png\n",
      "./sample_out_nopretrain/out_23.png\n",
      "./sample_out_nopretrain/out_24.png\n",
      "./sample_out_nopretrain/out_25.png\n",
      "./sample_out_nopretrain/out_26.png\n",
      "./sample_out_nopretrain/out_27.png\n",
      "./sample_out_nopretrain/out_28.png\n",
      "./sample_out_nopretrain/out_29.png\n",
      "./sample_out_nopretrain/out_30.png\n",
      "./sample_out_nopretrain/out_31.png\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "net = GazeNet()\n",
    "net.cuda()\n",
    "\n",
    "# Resuming Training\n",
    "resume_training = True\n",
    "resume_path = './saved_models/chong_gooreal_final/model_5epochs_notrain.tar'\n",
    "if resume_training:\n",
    "    net, _, _ = resume_checkpoint(net, None,resume_path)\n",
    "    #test(net, test_data_loader,logger, save_output=True)\n",
    "\n",
    "\n",
    "test_on_batch(net, test_data_loader, heatmap_size=64, save_dir='./sample_out_nopretrain/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
